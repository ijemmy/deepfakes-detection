{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crop and align faces\n",
    "\n",
    "**Objective:** Use detected face, its eyes locations, and `OpenCV` library to align the face to the desired eyes positions and scale it to the desired size. For the correct alignment and cropping/scaling, we need to decide on the desired size of the output face and its eye positions. The desired face size (its width and height), to which we crop and scale the detected bounding box is usually determined by the external factors. For instance, if we are preparing facial images for classification task by a face recognition neural network, then the selected neural network will require the input images to be of specific size. The desired face size is therefore a parameter of the system. As for the eye locations, they are typically expressed as ratios or percentages relative to the desired face size and these ratios determine how much of the face will be visible in the resulted image, i.e., how much into the face we will zoom.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.   Implement `crop_and_align()` which would have the following parameters: desired images size, desired eyes locations (as percentages to the total face size), image from which we extract face, and location of detected eyes.\n",
    "2.   Start by finding the angle between two eyes in the image. We will use this angle to rotate the image, so the eyes of all faces will become parallel to the bottom of the image. We can compute this in the function called `eyes_angle()`.\n",
    "3.   Using the current distance between eyes, the distance between the desired eyes (dictates the size of a face inside the resulted image), desired size of the final image, compute the scaling factor, which is the value by which we need to scale the detected faces for it to become of the desired size. We can compute this in the function called `scaling_factor()`.\n",
    "4.   Using function `getRotationMatrix2D()` from `OpenCV` compute rotation matrix.\n",
    "5.   Move the center of the eyes in the desired position and using `warpAffine()` function of `OpenCV` perform affine warp of the image resulting in the aligned and scaled face. \n",
    "6.   Save output aligned faces to disk as images (PNG is preferable, since it is a lossless format).\n",
    "\n",
    "### Step 4.1: Implement eyes_angle() function\n",
    "\n",
    "Find angle between the line connecting the centers of the eye and the bottom (the X-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "# some settings to make it smoothly runnable in Jupyter\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eyes_angle(left_eye, right_eye):\n",
    "    # find the distances between X and Y coordinates of both eyes\n",
    "    dY = right_eye[1] - left_eye[1]\n",
    "    dX = right_eye[0] - left_eye[0]\n",
    "    # compute the angle using trigonometry\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "    return angle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Implement scaling_factor() function\n",
    "\n",
    "Using the current distance between eyes, the distance between the desired eyes (dictates the size of a face inside the resulted images), desired size of the final image, compute the scaling factor, which is the value by which we need to scale the detected faces for it to become of the desired size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_factor(left_eye, right_eye, desired_left_eye, desired_right_eye):\n",
    "    # find the distances between X and Y coordinates of both eyes\n",
    "    dY = right_eye[1] - left_eye[1]\n",
    "    dX = right_eye[0] - left_eye[0]\n",
    "    # find the actual distance between eyes (the hypotenuse)\n",
    "    dist = np.sqrt((dX ** 2) + (dY ** 2))\n",
    "    # find the distance between X and Y coordinates in the desired face (which we will have after scaling)\n",
    "    desired_dY = desired_right_eye[1] - desired_left_eye[1]\n",
    "    desired_dX = desired_right_eye[0] - desired_left_eye[0]\n",
    "    # find the  distance between desired eye coordinates (the hypotenuse)\n",
    "    desired_dist = np.sqrt((desired_dX ** 2) + (desired_dY ** 2))\n",
    "    \n",
    "    # compute the ratio between distances, which is the scale factor\n",
    "    scaling_factor = desired_dist / dist\n",
    "    return scaling_factor\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3: Implement crop_and_align() function\n",
    "\n",
    "Using the computed angle and scaling_factor, rotate and scale the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_and_align(image, left_eye, right_eye, desired_image_width, \n",
    "                   desired_left_eye_percentage):\n",
    "    # find angle of the line between the eyes\n",
    "    angle = eyes_angle(left_eye, right_eye)\n",
    "\n",
    "    # assuming desired_left_eye_percentage tells where the eyes should be relative to the image size\n",
    "    # compute its actual place in the resulted image\n",
    "    desired_left_eye = (desired_left_eye_percentage[0]*desired_image_width, \n",
    "                        desired_left_eye_percentage[1]*desired_image_width)\n",
    "    # similar compute the mirror coordinates for desired_right_eye\n",
    "    desired_right_eye = ((1.0-desired_left_eye_percentage[0])*desired_image_width, \n",
    "                        desired_left_eye_percentage[1]*desired_image_width)\n",
    "\n",
    "    # find scaling factor based on where we want our eyes to be in the resulted image\n",
    "    scale = scaling_factor(left_eye, right_eye, desired_left_eye, desired_right_eye)\n",
    "    \n",
    "    # find the center point between two eyes, around which we will rotate the image\n",
    "    eyes_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "\n",
    "    # compute the rotation matrix using OpenCV, rotate and scale around the eyes_center\n",
    "    M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "\n",
    "    # move the current center of the eyes to the desired coordinates, which are\n",
    "    # mid point horizontally and the desired level vertically\n",
    "    tX = desired_image_width * 0.5\n",
    "    tY = desired_left_eye[1]\n",
    "    M[0, 2] += (tX - eyes_center[0])\n",
    "    M[1, 2] += (tY - eyes_center[1])\n",
    "\n",
    "    # by specifying height and width of the final image\n",
    "    # as our desired_image_width, we insruct warpAffine to cut off the extra pixels\n",
    "    w = desired_image_width\n",
    "    h = desired_image_width\n",
    "\n",
    "    # using OpenCV warpAffine() apply the M transformation, which will also crop the image\n",
    "    aligned = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    return aligned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4: Put everything together\n",
    "\n",
    "Using the code form previous milestone, loop through frames in a video, detect faces, align them, and crop them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "# detect one face and its eyes coordinates in the given image\n",
    "def detect_face(image, desired_size=224, desired_left_eye_percentage=(0.35, 0.35)):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    detection_result = detector.detect_faces(image_rgb)\n",
    "    left_eye = detection_result[0]['keypoints']['left_eye']\n",
    "    right_eye = detection_result[0]['keypoints']['right_eye']\n",
    "    face = crop_and_align(image, left_eye, right_eye, desired_size, desired_left_eye_percentage)\n",
    "    if face is not None:\n",
    "        return face\n",
    "    return None\n",
    "\n",
    "# loop through frames in the video and detect faces\n",
    "def detect_and_save_faces(video_path, limit_faces=-1, save_faces=True):\n",
    "    detector = MTCNN()\n",
    "    faces = list()\n",
    "    # add '_face' at the end to differentiate face images\n",
    "    face_name = os.path.splitext(video_path)[0] + '_face'\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for frame_no in range(num_frames):\n",
    "        # if the given limit is not -1, loop only until the limit\n",
    "        if limit_faces != -1 and frame_no >= limit_faces:\n",
    "            break\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "        ret, frame = cap.read()\n",
    "        # detect faces\n",
    "        face = detect_face(frame, desired_size=256, desired_left_eye_percentage=(0.35, 0.35))\n",
    "        if face is not None:\n",
    "            faces.append(face)\n",
    "            if save_faces:\n",
    "                cv2.imwrite(face_name + '_' + str(frame_no) + '.png', face)\n",
    "    return faces\n",
    "\n",
    "path_to_video = '/any/video/with/face'\n",
    "# save first 5 aligned and cropped faces of the video\n",
    "faces = detect_and_save_faces(path_to_video, limit_faces=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
